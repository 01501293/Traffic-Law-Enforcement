{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### conda install -c pytorch pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yFxkfy85UQGQ"
   },
   "outputs": [],
   "source": [
    "from elements.yolo import LINE_DETECTION\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "from time import time\n",
    "from skimage.feature import canny\n",
    "from skimage.transform import probabilistic_hough_line as phl\n",
    "from copy import deepcopy\n",
    "import math\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rad(degree):\n",
    "    return (degree * np.pi/180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LljXvFDCrlHi"
   },
   "outputs": [],
   "source": [
    "def line_detector_func(image, edges, theta_range=None):\n",
    "    line_image = 0 * image\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # canny edge detector filter\n",
    "    lines = phl(edges,\n",
    "                 threshold=threshold,\n",
    "                 line_length=max(image_gray.shape)//2,\n",
    "                 line_gap=max(image_gray.shape)//2,\n",
    "                 theta=theta_range,\n",
    "                 seed=2022)\n",
    "\n",
    "\n",
    "    idx = 0\n",
    "    while len(lines)>1 and idx<len(lines)-1:\n",
    "        (x00, y00), (x01, y01) = lines[idx]\n",
    "        (x10, y10), (x11, y11) = lines[idx+1]\n",
    "        m0 = (y01-y00) / (x01-x00)\n",
    "        m1 = (y11-y10) / (x11-x10)\n",
    "        if np.abs(m1-m0) <= tetha_thr:\n",
    "            lines.pop(idx+1)\n",
    "        else:\n",
    "            idx+=1\n",
    "    polar= []\n",
    "    for ((x0, y0), (x1, y1)) in lines: \n",
    "        thetar = np.arctan((y1+y0)/(x1+x0))\n",
    "        rho = np.sqrt(((x0+x1)/2)**2+((y0+y1)/2)**2)\n",
    "        polar.append([rho,thetar])\n",
    "        cv2.line(line_image, (x0, y0), (x1, y1), (255, 255, 255), thickness=thickness)\n",
    "    polar = np.array(polar)  \n",
    "    return line_image, lines, polar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.concatenate([np.arange(start=rad(-60),stop=rad(-5),step=rad(1)),np.arange(start=rad(5),stop=rad(60),step=rad(1))])\n",
    "tetha_thr = 0.5\n",
    "thickness = 2\n",
    "region_thr = 1000\n",
    "# canny hyoerparameters\n",
    "sigma = 5\n",
    "low_threshold = 1\n",
    "high_threshold = 25\n",
    "# probabilistic_hough_line hyperparameters\n",
    "threshold = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violations, if camera has rear view of the cars, it most be [0,1]. for front view of cars it will be [-2,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for line_sebghat viokation\n",
    "line_num = [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OWZXjdgCUUkc"
   },
   "outputs": [],
   "source": [
    "image = '/Users/Sean/Desktop/FYP/Code/Traffic-Law-Enforcement-main/test.jpg'\n",
    "# load image\n",
    "frame = cv2.imread(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9bmdRPCtUfBe",
    "outputId": "1a053eb9-82c1-4516-95e8-9f372545fb9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n"
     ]
    }
   ],
   "source": [
    "# detector objects\n",
    "line_detector = LINE_DETECTION('./weights/line_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rO5Iz5OrVRPT"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'line_detector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0s/nwnvg9pj6w3__dmw3vc7st580000gn/T/ipykernel_1118/1436929521.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# detection process, detecting lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbb_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# extract edges from whole image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimage_gray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'line_detector' is not defined"
     ]
    }
   ],
   "source": [
    "# detection process, detecting lines\n",
    "lines = line_detector.detect(frame)\n",
    "bb_mask = np.zeros((frame.shape))\n",
    "# extract edges from whole image\n",
    "image_gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "# canny edge detector filter\n",
    "edges = canny(image_gray,sigma=sigma,low_threshold=low_threshold,high_threshold=high_threshold)\n",
    "edges_3ch = np.zeros((frame.shape))\n",
    "edges_m = np.zeros((frame.shape))\n",
    "centre = []\n",
    "for line in lines:\n",
    "    [(xmin,ymin),(xmax,ymax)] = line['bbox']\n",
    "    [(xc,yc)]= line['centre']\n",
    "    centre.append([xc,yc])\n",
    "    for row in range(int(ymin),int(ymax)):\n",
    "        for col in range(int(xmin),int(xmax)):\n",
    "            if edges[row,col] == True:\n",
    "                edges_3ch[row,col,:] = 255\n",
    "centre = np.array(centre)\n",
    "# cv2.imwrite('03_edges.jpg', cv2.resize(edges_3ch,(edges.shape[1],edges.shape[0])))\n",
    "print(centre)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage import morphology as morph\n",
    "# ar = edges_3ch[:,:,1] >0\n",
    "# new_edges = morph.remove_small_objects(ar, 100, connectivity = 2)\n",
    "# newedges_3ch = np.zeros((frame.shape))\n",
    "# for row in range(new_edges.shape[0]):\n",
    "#     for col in range(new_edges.shape[1]):\n",
    "#         if new_edges[row,col] == True:\n",
    "#             newedges_3ch[row,col,:] = 255\n",
    "#         else:\n",
    "#             newedges_3ch[row,col,:] = 0\n",
    "            \n",
    "# cv2.imwrite('03_edges.jpg', cv2.resize(newedges_3ch,(edges.shape[1],edges.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line_image, lines, polar = line_detector_func(frame,new_edges,theta_range=None)\n",
    "\n",
    "# cv2.imwrite('05_lines.jpg', cv2.resize(line_image,(edges.shape[1],edges.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gray = cv2.cvtColor(line_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# cv2.imwrite('lines.jpg', cv2.resize(gray,(edges.shape[1],edges.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = polar.reshape(polar.shape[0],2)\n",
    "# print(centre)\n",
    "# print(lines.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing features to be in (0-1) range\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(centre)\n",
    "# centre = scaler.fit_transform(centre)\n",
    "X = np.array([[1, 2], [1, 4], [1, 0], [10, 2], [10, 4], [10, 0]])\n",
    "gm = GMM(n_components=2, random_state=0).fit(X)\n",
    "# gmm = GMM(n_components=5)\n",
    "# gmm.fit(centre)\n",
    "# labels = gmm.predict(centre)\n",
    "\n",
    "# centre = scaler.inverse_transform(centre) #getting back our original values\n",
    "\n",
    "# num_clusters = np.max(labels) + 1\n",
    "# print(num_clusters, \"clusters detected\")\n",
    "\n",
    "# for i, line in enumerate(centre):\n",
    "#     if labels[i] == 0:\n",
    "#         color = 'g'\n",
    "#     elif labels[i] == 1:\n",
    "#         color = 'b'\n",
    "#     elif labels[i] == 2:\n",
    "#         color = 'r'\n",
    "#     elif labels[i] == 3:\n",
    "#         color = 'y'\n",
    "#     elif labels[i] == 4:\n",
    "#         color = 'm'\n",
    "#     elif labels[i] == 5:\n",
    "#         color = 'c'\n",
    "#     elif labels[i] == -1:\n",
    "#         color = 'k'\n",
    "    \n",
    "    \n",
    "#     plt.scatter(line[0],line[1],c=color)\n",
    "    \n",
    "# plt.show()\n",
    "\n",
    "# grouped = defaultdict(list)\n",
    "# #grouping lines by clusters\n",
    "# for i, label in enumerate(labels):\n",
    "#     grouped[label].append([centre[i,0],centre[i,1]])\n",
    "\n",
    "# means = []\n",
    "# #getting mean values by cluster\n",
    "# for i in range(num_clusters):\n",
    "#     mean = np.mean(np.array(grouped[i]), axis=0)\n",
    "#     means.append(mean)\n",
    "# means = np.array(means)\n",
    "\n",
    "# #black dots are classified as noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = '/Users/Sean/Desktop/FYP/Code/Traffic-Law-Enforcement-main/test.jpg'\n",
    "# # load image\n",
    "# frame = cv2.imread(image)\n",
    "# img = deepcopy(frame)\n",
    "# print(means)\n",
    "# for rho, theta in means:\n",
    "#     a = math.cos(theta)\n",
    "#     b = math.sin(theta)\n",
    "#     x0 = a * rho\n",
    "#     y0 = b * rho\n",
    "#     pt1 = (int(x0 + 1000*(-b)), int(y0 + 1000*(a)))\n",
    "#     pt2 = (int(x0 - 1000*(-b)), int(y0 - 1000*(a)))\n",
    "#     img = cv2.line(img, pt1, pt2, (0,0,255), 2, cv2.LINE_AA)\n",
    "\n",
    "# cv2.imwrite('cluster.jpg', cv2.resize(img,(img.shape[1],img.shape[0])))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Mask_Generator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
